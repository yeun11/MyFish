{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "#학습 데이터셋 가져오기\n",
        "train_datasets = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/fish',\n",
        "    image_size = (250,250),\n",
        "    batch_size = 64,\n",
        "    subset = 'training',\n",
        "    validation_split=0.01,\n",
        "    label_mode='categorical',\n",
        "    seed = 1234\n",
        ")\n",
        "\n",
        "#테스트 데이터셋 가져오기\n",
        "test_datasets = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/fish',\n",
        "    image_size = (250,250),\n",
        "    batch_size = 64,\n",
        "    subset = 'validation',\n",
        "    validation_split=0.01,\n",
        "    label_mode='categorical',\n",
        "    seed = 1234\n",
        ")\n",
        "\n",
        "# ResNet50 불러오기\n",
        "base_model = ResNet50(include_top=False, pooling = 'avg' , input_shape = (250,250 ,3), weights = 'imagenet') #input shape 수정\n",
        "\n",
        "#학습 못 하게 하기\n",
        "for i in base_model.layers :\n",
        "  i.trainable = False\n",
        "\n",
        "\n",
        "#모델 layer 설계\n",
        "reshape_layer = tf.keras.layers.Reshape((1, 1, 2048))(base_model.output)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal')(reshape_layer)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomRotation(0.1)(x)\n",
        "x = tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "output = tf.keras.layers.Dense(135, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model_res = tf.keras.Model(base_model.input, output)\n",
        "\n",
        "\n",
        "# 모델 컴파일\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model_res.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy']) \n",
        "history = model_res.fit(train_datasets,validation_data=test_datasets, epochs=35) #학습하기\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxzUjfLWOM2d",
        "outputId": "3de54a5b-3309-428b-8597-565e7e4ad455"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18953 files belonging to 135 classes.\n",
            "Using 18764 files for training.\n",
            "Found 18953 files belonging to 135 classes.\n",
            "Using 189 files for validation.\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 250, 250, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 256, 256, 3)  0           ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 125, 125, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 125, 125, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 125, 125, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 127, 127, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 63, 63, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 63, 63, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 63, 63, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 63, 63, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 63, 63, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 63, 63, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 63, 63, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 63, 63, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 63, 63, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 63, 63, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 63, 63, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 63, 63, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 63, 63, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 63, 63, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 63, 63, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 63, 63, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 63, 63, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 63, 63, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 63, 63, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 63, 63, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 63, 63, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 63, 63, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 63, 63, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 63, 63, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 63, 63, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 63, 63, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 63, 63, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 63, 63, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 63, 63, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 63, 63, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 63, 63, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 63, 63, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 63, 63, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/35\n",
            "294/294 [==============================] - 69s 221ms/step - loss: 2.5115 - accuracy: 0.4381 - val_loss: 1.2793 - val_accuracy: 0.7037\n",
            "Epoch 2/35\n",
            "294/294 [==============================] - 66s 221ms/step - loss: 1.0304 - accuracy: 0.7506 - val_loss: 0.9337 - val_accuracy: 0.7778\n",
            "Epoch 3/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.6886 - accuracy: 0.8334 - val_loss: 0.8068 - val_accuracy: 0.7672\n",
            "Epoch 4/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.5190 - accuracy: 0.8755 - val_loss: 0.7476 - val_accuracy: 0.8042\n",
            "Epoch 5/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.4008 - accuracy: 0.9084 - val_loss: 0.6828 - val_accuracy: 0.8148\n",
            "Epoch 6/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.3298 - accuracy: 0.9270 - val_loss: 0.6837 - val_accuracy: 0.8095\n",
            "Epoch 7/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.2743 - accuracy: 0.9389 - val_loss: 0.6486 - val_accuracy: 0.8307\n",
            "Epoch 8/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.2288 - accuracy: 0.9502 - val_loss: 0.6485 - val_accuracy: 0.8042\n",
            "Epoch 9/35\n",
            "294/294 [==============================] - 66s 224ms/step - loss: 0.1989 - accuracy: 0.9575 - val_loss: 0.6383 - val_accuracy: 0.8148\n",
            "Epoch 10/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.1707 - accuracy: 0.9667 - val_loss: 0.6803 - val_accuracy: 0.8148\n",
            "Epoch 11/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.1531 - accuracy: 0.9691 - val_loss: 0.6186 - val_accuracy: 0.8254\n",
            "Epoch 12/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.1364 - accuracy: 0.9729 - val_loss: 0.6213 - val_accuracy: 0.8307\n",
            "Epoch 13/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.1254 - accuracy: 0.9755 - val_loss: 0.7151 - val_accuracy: 0.8095\n",
            "Epoch 14/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.1196 - accuracy: 0.9750 - val_loss: 0.6476 - val_accuracy: 0.8413\n",
            "Epoch 15/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0998 - accuracy: 0.9820 - val_loss: 0.6227 - val_accuracy: 0.8307\n",
            "Epoch 16/35\n",
            "294/294 [==============================] - 67s 224ms/step - loss: 0.0940 - accuracy: 0.9819 - val_loss: 0.6536 - val_accuracy: 0.8148\n",
            "Epoch 17/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0892 - accuracy: 0.9829 - val_loss: 0.6236 - val_accuracy: 0.8307\n",
            "Epoch 18/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.0811 - accuracy: 0.9841 - val_loss: 0.6603 - val_accuracy: 0.8413\n",
            "Epoch 19/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0815 - accuracy: 0.9828 - val_loss: 0.6973 - val_accuracy: 0.8307\n",
            "Epoch 20/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.0747 - accuracy: 0.9848 - val_loss: 0.6324 - val_accuracy: 0.8360\n",
            "Epoch 21/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.0694 - accuracy: 0.9865 - val_loss: 0.7160 - val_accuracy: 0.7937\n",
            "Epoch 22/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.0684 - accuracy: 0.9856 - val_loss: 0.6536 - val_accuracy: 0.8095\n",
            "Epoch 23/35\n",
            "294/294 [==============================] - 66s 224ms/step - loss: 0.0634 - accuracy: 0.9873 - val_loss: 0.6463 - val_accuracy: 0.8413\n",
            "Epoch 24/35\n",
            "294/294 [==============================] - 66s 224ms/step - loss: 0.0656 - accuracy: 0.9855 - val_loss: 0.6835 - val_accuracy: 0.8254\n",
            "Epoch 25/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0643 - accuracy: 0.9856 - val_loss: 0.7141 - val_accuracy: 0.8413\n",
            "Epoch 26/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0584 - accuracy: 0.9861 - val_loss: 0.7820 - val_accuracy: 0.8201\n",
            "Epoch 27/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0606 - accuracy: 0.9863 - val_loss: 0.7345 - val_accuracy: 0.8148\n",
            "Epoch 28/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0486 - accuracy: 0.9897 - val_loss: 0.6897 - val_accuracy: 0.8307\n",
            "Epoch 29/35\n",
            "294/294 [==============================] - 67s 226ms/step - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.7802 - val_accuracy: 0.8042\n",
            "Epoch 30/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0498 - accuracy: 0.9886 - val_loss: 0.8094 - val_accuracy: 0.8201\n",
            "Epoch 31/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0515 - accuracy: 0.9876 - val_loss: 0.7301 - val_accuracy: 0.8148\n",
            "Epoch 32/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0498 - accuracy: 0.9877 - val_loss: 0.6953 - val_accuracy: 0.8307\n",
            "Epoch 33/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0482 - accuracy: 0.9879 - val_loss: 0.7266 - val_accuracy: 0.8254\n",
            "Epoch 34/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0475 - accuracy: 0.9885 - val_loss: 0.7187 - val_accuracy: 0.8519\n",
            "Epoch 35/35\n",
            "294/294 [==============================] - 67s 225ms/step - loss: 0.0471 - accuracy: 0.9884 - val_loss: 0.7518 - val_accuracy: 0.8254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "T676lvhXFXZu",
        "outputId": "11c1aae5-93f4-44b7-c109-cddc93af1e00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-037f67ab10bf>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrand_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    781\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3009\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3012\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \"output_shapes\", output_shapes)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#테스트 데이터셋 테스트 코드\n",
        "\n",
        "import random\n",
        "\n",
        "class_name = ['가드네리 킬리피쉬', '고도비', '골든 구라미', '골든 바브', '골든 알지이터', '구피', '그린 네온 테트라', '글라스 블러드 핀 테트라', '글라스캣', '글로라이트 다니오', \n",
        "              '글로라이트 테트라', '나비 비파', '난주 금붕어', '남미 복어', '네온 드워프 레인보우', '네온 테트라', '뉴기니아 레인보우', '다람쥐 시클리드', '다이아몬드 테트라', \n",
        "              '드워프 구라미', '디스커스', '라스보라 갤럭시', '라스보라 에메랄드', '라스보라 쿠보타이', '라스보라 헤테로몰파', '라스보라 헹겔리', '라이어테일 몰리', '러미노즈 테트라', \n",
        "              '레드 레인보우', '레드 플래티', '레몬 테트라', '레오파드 다니오', '레인보우 샤크', '로즈라인 바브', '로지 바브', '리코리스 구라미', '마다가스카르 레인보우', '메티니스', \n",
        "              '메티니스 블랙바', '몽크호샤 코스테', '몽크호샤(레드아이 테트라)', '물티', '미키마우스 플래티', '바나나 시클리드', '백설 시클리드', '백운산', '밴디드 구라미', '밴디드 레인보우', \n",
        "              '밴디드 레포리너스', '버터플라이 레인보우', '벌룬 라미레지', '범블비 플래티', '베일테일 베타', '보세마니 레인보우', '볼리비안 라미레지', '브론즈 코리도라스', '브리샤르디', \n",
        "              '블랙 네온 테트라', '블랙 테트라(컬러 테트라)', '블루 레인보우', '블루 스팟 구라미', '블루 제브라 시클리드', '블루킹 테트라', '비너스투스 시클리드', '뽀본데타 레인보우', '샤페 테트라', \n",
        "              '선셋 구라미', '선셋 플래티', '세베럼', '셀핀 몰리', '소드테일', '수마트라', '스터바이 코리도라스', '스포티드 메티니스', '시아미즈 알지이터', '실버 구라미', '실버 바브', '실버 샤크', \n",
        "              '실버팁 테트라', '아이스블루 시클리드', '안시', '알리 시클리드', '알비노 코리도라스', '앰버 테트라', '엔젤피쉬', '엠페러 테트라', '오데사 바브', '오란다 금붕어', '오셀라투스', '왁 플래티', \n",
        "              '유금 금붕어', '인디언 복어', '저먼 라미레지', '제브라 다니오', '진주린 금붕어', '찬다랑가', '체리 바브', '초록 복어', '초콜릿 구라미', '카디널 테트라', '컨빅트 시클리드', '코메트 금붕어', \n",
        "              '코멧 플래티', '코발트 블루 구라미', '콜롬비아 테트라', '콩고 테트라', '쿨리 로치', '크라운 로치', '크라운 킬리피쉬', '키싱 구라미', '키티 테트라', '턱시도 플래티', '툭눈 금붕어', \n",
        "              '트로페우스 드보이시', '파키스탄 로치', '판다 플래티', '팔바 레인보우', '팬더 로치', '팬더 코리도라스', '펄 구라미', '페퍼드 코리도라스', '펭귄 테트라', '풍선 몰리', '프론토사', \n",
        "              '프리스텔라 리들레이', '플라워혼', '플라캇 베타', '플레임 테트라', '피그메우스 코리도라스', '피그미 구라미', '피콕 시클리드', '하스타투스 코리도라스', '하프문 베타', '허니 구라미', '혈앵무']\n",
        "\n",
        "\n",
        "# 랜덤 이미지 선택\n",
        "num_images = len(test_datasets)\n",
        "rand_idx = random.randint(0, num_images-1)\n",
        "image, label = list(test_datasets.take(1))[0]\n",
        "\n",
        "for image_batch, label_batch in test_datasets.take(1):\n",
        "    # 모델 예측\n",
        "    predictions = model_res.predict(image_batch) # 64개 한꺼번에 예측\n",
        "    \n",
        "    for i in range(len(label_batch)):\n",
        "        predicted_classes = np.argsort(predictions[i])[::-1][:5]\n",
        "        print(f'정답 :  {class_name[np.argmax(label_batch[i])]}\\nTop 5 물고기 :')\n",
        "        for idx in predicted_classes:\n",
        "            print(f\" - {class_name[idx]}: {predictions[i][idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyHVW6SWOznI",
        "outputId": "e07846c1-83ad-41d0-b31f-4cc19ab64c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#모델 저장하는 코드\n",
        "\n",
        "model_res.save('drive/MyDrive/models/model5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DOTwnP71e_wP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e9c479-90e6-4f9b-f2b3-2f9b56cff926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15963 sha256=dac8b8cc62b294791c9079b71a4140f845d00e832955aa941e754bb751b85b8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.27.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.2)\n",
            "Installing collected packages: flask_ngrok\n",
            "Successfully installed flask_ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "#ngrok설치\n",
        "!pip install pyngrok==4.1.1\n",
        "!pip install flask_ngrok\n",
        "\n",
        "#서버 코드\n",
        "import numpy as np\n",
        "from io import BytesIO \n",
        "from flask_ngrok import run_with_ngrok\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from flask import Flask, request, jsonify\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class_name = ['가드네리 킬리피쉬', '고도비', '골든 구라미', '골든 바브', '골든 알지이터', '구피', '그린 네온 테트라', '글라스 블러드 핀 테트라', '글라스캣', '글로라이트 다니오', \n",
        "              '글로라이트 테트라', '나비 비파', '난주 금붕어', '남미 복어', '네온 드워프 레인보우', '네온 테트라', '뉴기니아 레인보우', '다람쥐 시클리드', '다이아몬드 테트라', \n",
        "              '드워프 구라미', '디스커스', '라스보라 갤럭시', '라스보라 에메랄드', '라스보라 쿠보타이', '라스보라 헤테로몰파', '라스보라 헹겔리', '라이어테일 몰리', '러미노즈 테트라', \n",
        "              '레드 레인보우', '레드 플래티', '레몬 테트라', '레오파드 다니오', '레인보우 샤크', '로즈라인 바브', '로지 바브', '리코리스 구라미', '마다가스카르 레인보우', '메티니스', \n",
        "              '메티니스 블랙바', '몽크호샤 코스테', '몽크호샤(레드아이 테트라)', '물티', '미키마우스 플래티', '바나나 시클리드', '백설 시클리드', '백운산', '밴디드 구라미', '밴디드 레인보우', \n",
        "              '밴디드 레포리너스', '버터플라이 레인보우', '벌룬 라미레지', '범블비 플래티', '베일테일 베타', '보세마니 레인보우', '볼리비안 라미레지', '브론즈 코리도라스', '브리샤르디', \n",
        "              '블랙 네온 테트라', '블랙 테트라(컬러 테트라)', '블루 레인보우', '블루 스팟 구라미', '블루 제브라 시클리드', '블루킹 테트라', '비너스투스 시클리드', '뽀본데타 레인보우', '샤페 테트라', \n",
        "              '선셋 구라미', '선셋 플래티', '세베럼', '셀핀 몰리', '소드테일', '수마트라', '스터바이 코리도라스', '스포티드 메티니스', '시아미즈 알지이터', '실버 구라미', '실버 바브', '실버 샤크', \n",
        "              '실버팁 테트라', '아이스블루 시클리드', '안시', '알리 시클리드', '알비노 코리도라스', '앰버 테트라', '엔젤피쉬', '엠페러 테트라', '오데사 바브', '오란다 금붕어', '오셀라투스', '왁 플래티', \n",
        "              '유금 금붕어', '인디언 복어', '저먼 라미레지', '제브라 다니오', '진주린 금붕어', '찬다랑가', '체리 바브', '초록 복어', '초콜릿 구라미', '카디널 테트라', '컨빅트 시클리드', '코메트 금붕어', \n",
        "              '코멧 플래티', '코발트 블루 구라미', '콜롬비아 테트라', '콩고 테트라', '쿨리 로치', '크라운 로치', '크라운 킬리피쉬', '키싱 구라미', '키티 테트라', '턱시도 플래티', '툭눈 금붕어', \n",
        "              '트로페우스 드보이시', '파키스탄 로치', '판다 플래티', '팔바 레인보우', '팬더 로치', '팬더 코리도라스', '펄 구라미', '페퍼드 코리도라스', '펭귄 테트라', '풍선 몰리', '프론토사', \n",
        "              '프리스텔라 리들레이', '플라워혼', '플라캇 베타', '플레임 테트라', '피그메우스 코리도라스', '피그미 구라미', '피콕 시클리드', '하스타투스 코리도라스', '하프문 베타', '허니 구라미', '혈앵무']\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = tf.keras.models.load_model('drive/MyDrive/models/model6')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # 이미지 파일을 업로드 받음\n",
        "    img = BytesIO(request.files['image'].read())\n",
        "\n",
        "    # 이미지 전처리\n",
        "    img = image.load_img(img, target_size=(250, 250))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    # 모델 예측\n",
        "    predictions = model.predict(x)\n",
        "    predicted_classes = np.argsort(predictions[0])[::-1][:5]  # 사진 예측에서 값이 큰 순서대로 상위 5개 인덱스 가져오기\n",
        "\n",
        "    #colab에서 결과 확인 & 물고기 이름 배열에 추가\n",
        "    print(\"Top 5 물고기 : \")\n",
        "    rank = []\n",
        "    for idx in predicted_classes: #상위 5개 인덱스\n",
        "        rank.append(class_name[idx]) #물고기 이름을 결과에 추가\n",
        "        print(\" - \", class_name[idx], \": \", predictions[0][idx])\n",
        "\n",
        "\n",
        "    #예측 결과 반환\n",
        "    print(\"결과: \",rank[0], rank[1],rank[2]) \n",
        "    return jsonify({'prediction1': rank[0], 'prediction2' : rank[1], 'prediction3' : rank[2], 'prediction4' : rank[3], 'prediction5' : rank[4]})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWL1D8Tkjc3E",
        "outputId": "bd5a183f-651f-4440-c3ba-55d50cedd039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://cb64-34-126-70-206.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:45:52] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  플라캇 베타 :  0.52143574\n",
            " -  블랙 테트라(컬러 테트라) :  0.1700926\n",
            " -  풍선 몰리 :  0.12727787\n",
            " -  피콕 시클리드 :  0.12257902\n",
            " -  콜롬비아 테트라 :  0.03280408\n",
            "결과:  플라캇 베타 블랙 테트라(컬러 테트라) 풍선 몰리\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:46:06] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  혈앵무 :  0.96204984\n",
            " -  난주 금붕어 :  0.03524839\n",
            " -  디스커스 :  0.0017025147\n",
            " -  진주린 금붕어 :  0.00070663076\n",
            " -  백설 시클리드 :  0.00017888381\n",
            "결과:  혈앵무 난주 금붕어 디스커스\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:46:18] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  메티니스 블랙바 :  0.77088237\n",
            " -  블랙 테트라(컬러 테트라) :  0.07199121\n",
            " -  콜롬비아 테트라 :  0.07025249\n",
            " -  키싱 구라미 :  0.05677009\n",
            " -  블루 스팟 구라미 :  0.012515782\n",
            "결과:  메티니스 블랙바 블랙 테트라(컬러 테트라) 콜롬비아 테트라\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:46:33] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  엔젤피쉬 :  0.99975055\n",
            " -  코메트 금붕어 :  0.00013994842\n",
            " -  메티니스 블랙바 :  8.3377e-05\n",
            " -  툭눈 금붕어 :  1.1219852e-05\n",
            " -  레몬 테트라 :  4.919161e-06\n",
            "결과:  엔젤피쉬 코메트 금붕어 메티니스 블랙바\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:46:50] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  찬다랑가 :  0.99962294\n",
            " -  메티니스 블랙바 :  0.00022738088\n",
            " -  블랙 테트라(컬러 테트라) :  9.959897e-05\n",
            " -  엔젤피쉬 :  4.8505957e-05\n",
            " -  키싱 구라미 :  4.4139654e-07\n",
            "결과:  찬다랑가 메티니스 블랙바 블랙 테트라(컬러 테트라)\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:47:06] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  코메트 금붕어 :  0.42134884\n",
            " -  아이스블루 시클리드 :  0.3679938\n",
            " -  피콕 시클리드 :  0.07378365\n",
            " -  백설 시클리드 :  0.061790287\n",
            " -  블랙 테트라(컬러 테트라) :  0.058426652\n",
            "결과:  코메트 금붕어 아이스블루 시클리드 피콕 시클리드\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:47:15] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  체리 바브 :  0.57807\n",
            " -  알리 시클리드 :  0.23149341\n",
            " -  레몬 테트라 :  0.09883163\n",
            " -  아이스블루 시클리드 :  0.06513901\n",
            " -  글로라이트 테트라 :  0.0072631827\n",
            "결과:  체리 바브 알리 시클리드 레몬 테트라\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:47:29] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  마다가스카르 레인보우 :  0.9918783\n",
            " -  글로라이트 다니오 :  0.002790404\n",
            " -  백운산 :  0.0008711929\n",
            " -  카디널 테트라 :  0.00085009146\n",
            " -  엠페러 테트라 :  0.00072626444\n",
            "결과:  마다가스카르 레인보우 글로라이트 다니오 백운산\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:47:50] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  허니 구라미 :  0.40740088\n",
            " -  코발트 블루 구라미 :  0.2644917\n",
            " -  아이스블루 시클리드 :  0.13830256\n",
            " -  선셋 구라미 :  0.097127885\n",
            " -  블루킹 테트라 :  0.02761867\n",
            "결과:  허니 구라미 코발트 블루 구라미 아이스블루 시클리드\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:48:10] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  블루 제브라 시클리드 :  0.65327084\n",
            " -  컨빅트 시클리드 :  0.31349465\n",
            " -  혈앵무 :  0.014251809\n",
            " -  구피 :  0.007612346\n",
            " -  플라캇 베타 :  0.0040137013\n",
            "결과:  블루 제브라 시클리드 컨빅트 시클리드 혈앵무\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:48:28] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  블루킹 테트라 :  0.3504613\n",
            " -  그린 네온 테트라 :  0.245339\n",
            " -  글로라이트 테트라 :  0.21561839\n",
            " -  글라스캣 :  0.05383365\n",
            " -  글로라이트 다니오 :  0.030779446\n",
            "결과:  블루킹 테트라 그린 네온 테트라 글로라이트 테트라\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:48:47] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  비너스투스 시클리드 :  0.78441083\n",
            " -  엔젤피쉬 :  0.11273208\n",
            " -  블루 스팟 구라미 :  0.054665342\n",
            " -  인디언 복어 :  0.021335954\n",
            " -  라이어테일 몰리 :  0.0069193286\n",
            "결과:  비너스투스 시클리드 엔젤피쉬 블루 스팟 구라미\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:49:09] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  라이어테일 몰리 :  0.9947233\n",
            " -  엔젤피쉬 :  0.0047858334\n",
            " -  풍선 몰리 :  0.00017317568\n",
            " -  벌룬 라미레지 :  0.00015580557\n",
            " -  왁 플래티 :  5.576306e-05\n",
            "결과:  라이어테일 몰리 엔젤피쉬 풍선 몰리\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:49:33] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  비너스투스 시클리드 :  0.56199026\n",
            " -  볼리비안 라미레지 :  0.29315096\n",
            " -  엔젤피쉬 :  0.05559323\n",
            " -  벌룬 라미레지 :  0.029137785\n",
            " -  트로페우스 드보이시 :  0.026977256\n",
            "결과:  비너스투스 시클리드 볼리비안 라미레지 엔젤피쉬\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:49:50] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  드워프 구라미 :  0.95838875\n",
            " -  플라캇 베타 :  0.026401008\n",
            " -  디스커스 :  0.007331016\n",
            " -  피콕 시클리드 :  0.004288919\n",
            " -  풍선 몰리 :  0.0018404642\n",
            "결과:  드워프 구라미 플라캇 베타 디스커스\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:50:08] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  실버 구라미 :  0.9998405\n",
            " -  레인보우 샤크 :  3.8740098e-05\n",
            " -  콜롬비아 테트라 :  2.6034704e-05\n",
            " -  키싱 구라미 :  2.5112013e-05\n",
            " -  고도비 :  2.2555625e-05\n",
            "결과:  실버 구라미 레인보우 샤크 콜롬비아 테트라\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:50:23] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  디스커스 :  0.9999989\n",
            " -  피콕 시클리드 :  6.456619e-07\n",
            " -  혈앵무 :  2.3042739e-07\n",
            " -  보세마니 레인보우 :  6.287003e-08\n",
            " -  컨빅트 시클리드 :  1.7916246e-08\n",
            "결과:  디스커스 피콕 시클리드 혈앵무\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:50:57] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  피그메우스 코리도라스 :  0.98729104\n",
            " -  시아미즈 알지이터 :  0.008839134\n",
            " -  하스타투스 코리도라스 :  0.0026999644\n",
            " -  블랙 네온 테트라 :  0.00038503727\n",
            " -  라스보라 헹겔리 :  0.00023156742\n",
            "결과:  피그메우스 코리도라스 시아미즈 알지이터 하스타투스 코리도라스\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:51:16] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  블루 스팟 구라미 :  0.99950755\n",
            " -  혈앵무 :  0.00033473957\n",
            " -  컨빅트 시클리드 :  9.6407945e-05\n",
            " -  엔젤피쉬 :  2.9381457e-05\n",
            " -  플라캇 베타 :  1.5538262e-05\n",
            "결과:  블루 스팟 구라미 혈앵무 컨빅트 시클리드\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/May/2023 13:51:50] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 물고기 : \n",
            " -  블루킹 테트라 :  0.9564995\n",
            " -  글라스 블러드 핀 테트라 :  0.021057885\n",
            " -  레몬 테트라 :  0.0084320465\n",
            " -  샤페 테트라 :  0.0056800796\n",
            " -  실버팁 테트라 :  0.0029920184\n",
            "결과:  블루킹 테트라 글라스 블러드 핀 테트라 레몬 테트라\n"
          ]
        }
      ],
      "source": [
        "#서버 실행\n",
        "\n",
        "run_with_ngrok(app)\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}